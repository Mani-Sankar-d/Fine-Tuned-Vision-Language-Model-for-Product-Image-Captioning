The base BLIP model is trained on general imageâ€“text pairs.
We fine-tuned it on 10K curated fashion product images (from the Kaggle Fashion Product Images Dataset) to specialize it for apparel captioning.

        Model	          BLEU	METEOR
Zero-shot (Base BLIP)	  0.0	  0.13
Fine-tuned BLIP (Ours)	0.0	  0.89

ğŸŸ¢ Result: Over a 6.7Ã— improvement in semantic accuracy (METEOR)
Fine-tuned model now understands terms like "men blue t-shirt for sports wear" instead of generic "a man wearing clothes."

fashion-image-captioning/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ fashion-dataset/
â”‚       â”œâ”€â”€ images/                       # Original Kaggle images
â”‚       â”œâ”€â”€ subset_images/                # 10K sampled images
â”‚       â”œâ”€â”€ styles.csv                    # Original metadata
â”‚       â””â”€â”€ product_captions_filtered.csv # Final subset CSV (used for training)
â”‚
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ train_dataset.py                  # Dataset class for training
â”‚   â””â”€â”€ test_dataset.py                   # Dataset class for evaluation
â”‚
â”œâ”€â”€ fine_tuned_blip_fashion/              # Saved fine-tuned model (auto-created)
â”‚
â”œâ”€â”€ finetune.py                           # Fine-tuning script             
â”œâ”€â”€ requirements.txt                      # All dependencies
â””â”€â”€ README.md                             # Project documentation


ğŸ“¦ Dataset Preparation

Youâ€™ll need the Fashion Product Images (Small) dataset from Kaggle:
ğŸ‘‰ https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small

ğŸ§¾ Step 1. Download the dataset

Make sure you have the Kaggle CLI installed and configured:

pip install kaggle


Then run:

kaggle datasets download -d paramaggarwal/fashion-product-images-small
unzip fashion-product-images-small.zip -d data/fashion-dataset/


This creates:

data/fashion-dataset/
 â”œâ”€â”€ images/
 â”œâ”€â”€ styles.csv

âœ‚ï¸ Step 2. Create a 10K subset and generate captions

Run subset_sampler.py once â€” it will:

Randomly sample 10,000 rows from styles.csv

Copy the corresponding images into a new folder

Build a caption using gender, color, article type, and usage

Save everything as product_captions_filtered.csv


ğŸ“ Resulting directory

After running the script, folder should look like this:

data/fashion-dataset/
 â”œâ”€â”€ images/                 # full dataset
 â”œâ”€â”€ subset_images/          # 10K sampled images
 â”œâ”€â”€ styles.csv              # original metadata
 â””â”€â”€ product_captions_filtered.csv  # ready for training

# Step3. Execute finetune.py 


